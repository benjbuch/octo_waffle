---
title: "Import, Export, Save Routines"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***

To make your data analysis as reproducible as possible, you should try to not ‘physically manipulate’ the files with your raw data on the hard drive. Instead, aim to ‘import’ this data with a scripting language such as R and document all operations required for your analysis by writing down a ‘script’. The manipulated data will then be written to a new file. This may embrace anything from a cleaned-up version of the data in the same file format, a table with summary statistics, or the graphs you would like to include in your records.

## Navigating the Directory

> Paths and directories are different if you run Linux/macOS (‘Unix-like’) or Windows on your machine. The most important difference is that components of a path (folder and file names) are separated with a slash under Unix-like (e.g. `data/treasure_map.pdf`) and with backslash under Windows (e.g. `data\treasure_map.pdf`). Either are accepted by R, but because of their special meaning, backslashes have to be escaped as `\\` to work properly. Therefore, simply use regular slashes (`/`).

We will _always_ use relative paths in scripts and analyses. Absolute paths (starting with `C:\` or `\\servername` under Windows or `/` under Unix).

* In file paths, the current working directory is indicated with `.`, so that sub-folders are accessed via `./sub-folder/file.csv`.
* In file paths, `..` refers to the enclosing folder, so that `../../` moves you two folders out; wherever this is.

You can check the current working in your R session with `getwd()`.

You can change the current working directory with `setwd("filepath")`, although it is smarter to use `.Rproj` files to manage your projects. These automatically set appropriate working directories (the enclosing folder of the `.Rproj` file) and make sure multiple R projects can coexist without undesired inference.

## Getting Data into R

R offers a variety of functions to import data from files, ranging from plain text (`.txt`, `.csv`, `.tsv`, `.xml`, `.json`), file standards e.g. for sequencing data (`.fastq`, `.sam`, `.bam`) and flow-cytometry (`.fcs`), but also file formats generated by commercial software such as Microsoft Excel (`.xlsx`) and SAP's SPSS Statics (`.sav`).

It is also possible to download data directly from online resources, which might help to keep your analysis up-to-date.

If you do not have data at hand, R (and nearly each and every package) provides you with a variety of sample data sets. To see a list of these, just type `data()`.

### A Brief Remark on Names

Before we move on to load data into R, it might be useful to go over the following checklist that will make it easier to import the data correctly into R.

* Avoid names containing special characters such as `?`, `!`, `$`, `%`, `^`, `&`, `*`, `-`, `#`, `,`, `>`, `<`, `/`, etc. as well as any sorts of brackets.

    Fun fact: Diacritics and umlaut are fine for R, but rather unconventional.
    
* Avoid names (or values) with blank spaces, this can cause confusion during import.
* If you want to use multi-word names and values, stick to [one of the following styles](part_30-good_practices.md): `CellNumber`, `cell.number`, or `cell_number`.
* Short names are preferred over longer names.

### A Brief Remark on Large Files

Some files, such as sequencing data, can be very large in nature, often exceeding your computer's memory. It is typically not a good idea, to import them as ‘plain text’ into R. Instead, there are either specialized command-line tools (outside R) or packages (within R) that implement data classes which will load only the bits required for the current task into the memory and free slots as soon as they are no longer in use. 

<!-- here go some examples -->

### Import Delimited

In R, there are several ways to import data from delimited files, including

* in base R, `utils::read.csv(...)` for CSV and the more general `utils::read.delim(...)`,
* in the tidyverse, `readr::read_csv(...)` and `readr::read_delim(...)`, and
* `data.table::fread(...)` which is the fastes and most flexible of all the options and will handle a variety of scenarios for you on the fly.

Note that all these functions expect that **every row has the same number of columns**. Failure to meet this criterion will result in a warning or an error message.

Small files can conveniently be imported using `readr::read_csv(...)` as outlined in [the ‘Importing and Tidying Tabulated Data’](part_11-tidying_tables.md) section.

Here is the fast (and preferred) approach to import large files, e.g. `.csv` files exported from a FACS software, using `data.table::fread` (especially if you have many files).

```{r eval=FALSE}
FACS_data <- sapply(list.files("./part_40-import_export_save_files", pattern = "^FACS", full.names = TRUE), 
                    data.table::fread, fill = TRUE, check.names = TRUE,
                    # any unwanted column
                    drop = c("FSC-H", "FSC-W", "Cy5-A", "PerCP-Cy5.5-A", "PE-Cy7-A", "Index"),
                    USE.NAMES = TRUE, simplify = FALSE) %>% 
  data.table::rbindlist(idcol = "group") %>% 
  # keep track of the file identifier
  mutate(group = str_extract(group, "(?<=FACS-).+(?=\\.csv)")) %>% 
  # optionally convert into dplyr's data.frame class
  as_tibble()
```

## Exporting Data

An equivalent function to write out `.csv` files is `readr::write_csv`.

## Saving R Objects

Single R objects can be saved and restored (quite possibly under a different name) as follows.

```{r eval=FALSE}
# save a object x as rds
saveRDS(x, file = "filepath/my_fancy_object_x.rds")
# restore it under a different name
readRDS("filepath/my_fancy_object_x.rds") -> x_from_peter
```

If you want to save your entire workspace (‘Global Environment’) or parts of it, including object names, follow these lines.

```{r eval=FALSE}
# save entire workspace
save.image(file = "YYMMDD-my_backup.RData")
# save only some objects
save(x, y, my_function, df, file = "general_text_methods.RData")
```

Note that R (and RStudio) will ask you whether you would like to save your entire workspace in a _hidden_ file called ‘.RData’ in the current working directory.

If you have a proper R script for your data analysis, there should be no need to rely on saving and restoring a snapshot of a previous R session. Since R will restore ‘.RData’ automatically from the current working directory at the beginning of each session, not saving such images also avoids loading unwanted data in the ‘Global Environment’.